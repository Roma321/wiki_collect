{
    "task": "Некоторые желательные свойства функций активации:\n<<<Нелинейность – Если функция активации нелинейна, можно доказать, что двухуровневая нейронная сеть будет универсальным аппроксиматором функции . Тождественная функция активации не удовлетворяет этому свойству. Если несколько уровней используют тождественную функцию активации, вся сеть эквивалентна одноуровневой модели.\nНепрерывная дифференцируемость – Это свойство желательно  для обеспечения методов оптимизации на основе градиентного спуска. Двоичная ступенчатая функция активации не дифференцируема в точке 0 и её производная равна 0 во всех других точках, так что методы градиентного спуска не дают никакого успеха для неё.\nОбласть значений – Если множество значений функции активации ограничено, методы обучения на основе градиента более стабильны, поскольку представления эталонов существенно влияют лишь на ограниченный набор весов связей. Если область значений бесконечна, обучение, как правило, более эффективно, поскольку представления эталонов существенно влияют на большинство весов. В последнем случае обычно необходим меньший темп обучения.\nМонотонность – Если функция активации монотонна, поверхность ошибок, ассоциированная с одноуровневой моделью, гарантированно будет выпуклой .\nГладкие функции с монотонной производной – Показано, что в некоторых случаях они обеспечивают более высокую степень общности.\nАппроксимирует тождественную функцию около начала координат – Если функции активации имеют это свойство, нейронная сеть будет обучаться эффективно, если её веса инициализированы малыми случайными значениями. Если функция активации не аппроксимирует тождество около начала координат, нужно быть осторожным при инициализации весов. В таблице ниже функции активации, у которых \n\n\n\nf\n\n=\n0\n\n\n{\\displaystyle f=0}\n\n, \n\n\n\n\nf\n′\n\n\n=\n1\n\n\n{\\displaystyle f'=1}\n\n и \n\n\n\n\nf\n′\n\n\n\n{\\displaystyle f'}\n\n непрерывна в точке 0, помечены как имеющие это свойство.>>>",
    "correct": [
        [
            "Нелинейность – Если функция активации нелинейна, можно доказать, что двухуровневая нейронная сеть будет универсальным аппроксиматором функции . Тождественная функция активации не удовлетворяет этому свойству. Если несколько уровней используют тождественную функцию активации, вся сеть эквивалентна одноуровневой модели.",
            "Непрерывная дифференцируемость – Это свойство желательно  для обеспечения методов оптимизации на основе градиентного спуска. Двоичная ступенчатая функция активации не дифференцируема в точке 0 и её производная равна 0 во всех других точках, так что методы градиентного спуска не дают никакого успеха для неё.",
            "Область значений – Если множество значений функции активации ограничено, методы обучения на основе градиента более стабильны, поскольку представления эталонов существенно влияют лишь на ограниченный набор весов связей. Если область значений бесконечна, обучение, как правило, более эффективно, поскольку представления эталонов существенно влияют на большинство весов. В последнем случае обычно необходим меньший темп обучения.",
            "Монотонность – Если функция активации монотонна, поверхность ошибок, ассоциированная с одноуровневой моделью, гарантированно будет выпуклой .",
            "Гладкие функции с монотонной производной – Показано, что в некоторых случаях они обеспечивают более высокую степень общности.",
            "Аппроксимирует тождественную функцию около начала координат – Если функции активации имеют это свойство, нейронная сеть будет обучаться эффективно, если её веса инициализированы малыми случайными значениями. Если функция активации не аппроксимирует тождество около начала координат, нужно быть осторожным при инициализации весов. В таблице ниже функции активации, у которых ",
            "f",
            "=",
            "0",
            "{\\displaystyle f=0}",
            ", ",
            "f",
            "′",
            "=",
            "1",
            "{\\displaystyle f'=1}",
            " и ",
            "f",
            "′",
            "{\\displaystyle f'}",
            " непрерывна в точке 0, помечены как имеющие это свойство."
        ]
    ],
    "wrong": [],
    "meta": {
        "type": "ul",
        "link": "https://ru.wikipedia.org/wiki/Функция_активации"
    }
}